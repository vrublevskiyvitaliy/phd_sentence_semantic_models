{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ddb7578",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All imports should be here\n",
    "from huggingface_hub.hf_api import HfFolder\n",
    "from datasets import load_dataset\n",
    "from datasets import Dataset\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce3d95f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Privacy\n",
    "huggingface_token = '<TOKEN>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb5fc209",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config \n",
    "# File name that is used to store all processed sentances\n",
    "file_name_summary_all_sentances = 'all_sentances_processed.pkl'\n",
    "\n",
    "# New dataset name\n",
    "new_dataset_name = \"VitaliiVrublevskyi/mrpc_llama_2_v2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a764e17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log in the HF to get access to the dataset\n",
    "HfFolder.save_token(huggingface_token)\n",
    "\n",
    "dataset = load_dataset(\"glue\", \"mrpc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "afd5a72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_already_processed_sentances():\n",
    "    try:\n",
    "        with open(file_name_summary_all_sentances, 'rb') as file:\n",
    "            processed_sentances = pickle.load(file)\n",
    "    except:\n",
    "        processed_sentances = {}\n",
    "    return processed_sentances\n",
    "\n",
    "processed_sentances = load_already_processed_sentances()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e95ca130",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_sentances_from_dataset(dataset):\n",
    "    all_sentances = set()\n",
    "    \n",
    "    for part in ['train']:\n",
    "      for elem in dataset[part]:\n",
    "        all_sentances.add(elem['sentence1'])\n",
    "        all_sentances.add(elem['sentence2'])\n",
    "    \n",
    "    return list(all_sentances)\n",
    "\n",
    "all_sentances = get_all_sentances_from_dataset(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ffa4bf6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clean_summaries():\n",
    "    clean_summaries = {}\n",
    "    for s in all_sentances:\n",
    "        summaries = []\n",
    "        for p in processed_sentances[s]:  \n",
    "            index = p.find('Answer:') + len('Answer:') + 1\n",
    "            potential_summary = p[index:]\n",
    "            # It may be too big, so we need to trim it\n",
    "            index = potential_summary.find(\"\\n\")\n",
    "            potential_summary = potential_summary[:index]\n",
    "            potential_summary = potential_summary.replace(' a concise summary of this text in 20 words:', '')\n",
    "            summaries.append(potential_summary)\n",
    "        clean_summaries[s] = summaries\n",
    "    \n",
    "    return clean_summaries\n",
    "\n",
    "clean_summaries = get_clean_summaries()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "202c1696",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1920b4461f7e4e969e417fd244d952f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def enriched_train_set_generator():\n",
    "    train_set = []\n",
    "    for s in dataset['train']:\n",
    "        first_summaries = clean_summaries[s['sentence1']]\n",
    "        second_summaries = clean_summaries[s['sentence2']]\n",
    "        \n",
    "        first_summaries.append(s['sentence1'])\n",
    "        second_summaries.append(s['sentence2'])\n",
    "        # Only unique\n",
    "        first_summaries = list(set(first_summaries))\n",
    "        second_summaries = list(set(second_summaries))\n",
    "        \n",
    "        for s1 in first_summaries:\n",
    "            for s2 in second_summaries:\n",
    "                elem = {}\n",
    "                elem['label'] = s['label']\n",
    "                elem['sentence1'] = s1\n",
    "                elem['sentence2'] = s2\n",
    "                elem['category'] = 'llama2'\n",
    "                yield elem\n",
    "\n",
    "enriched_dataset_train = Dataset.from_generator(enriched_train_set_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "996cd050",
   "metadata": {},
   "outputs": [],
   "source": [
    "def enriched_validation_set_generator():\n",
    "    validation_set = []\n",
    "    for s in dataset['validation']:\n",
    "        elem = {}\n",
    "        elem['label'] = s['label']\n",
    "        elem['sentence1'] = s['sentence1']\n",
    "        elem['sentence2'] = s['sentence2']\n",
    "        elem['category'] = 'original'\n",
    "        yield elem\n",
    "        \n",
    "enriched_dataset_validation = Dataset.from_generator(enriched_validation_set_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "42cae032",
   "metadata": {},
   "outputs": [],
   "source": [
    "def enriched_test_set_generator():\n",
    "    validation_set = []\n",
    "    for s in dataset['test']:\n",
    "        elem = {}\n",
    "        elem['label'] = s['label']\n",
    "        elem['sentence1'] = s['sentence1']\n",
    "        elem['sentence2'] = s['sentence2']\n",
    "        elem['category'] = 'original'\n",
    "        yield elem\n",
    "        \n",
    "enriched_dataset_test = Dataset.from_generator(enriched_test_set_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f9412d6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "621bf56b759d4d76a14eff0070a1eab6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pushing dataset shards to the dataset hub:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d8f18b2bd7248dab738ab7d83acabb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/28 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b632f98e2ba04ccaaf5b676c20101fb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pushing dataset shards to the dataset hub:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93b5f9f2d7084172b8b0742bb650c8c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d0ba3153bd540908c1d52cfbb42842c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading metadata:   0%|          | 0.00/557 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60ef4f86cfe742bfbda0065008009a67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pushing dataset shards to the dataset hub:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08b995571fb24544a6e706a24ae0061d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42cd5df55d764af8a677c32385e8ee03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading metadata:   0%|          | 0.00/672 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "enriched_dataset_train.push_to_hub(new_dataset_name, split='train')\n",
    "enriched_dataset_validation.push_to_hub(new_dataset_name, split='validation')\n",
    "enriched_dataset_test.push_to_hub(new_dataset_name, split='test')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9af8624e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81504bd1a2564b569d5ce46bff0b0de8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/770 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f60c74d77b14c6ab8e79f53dfb9b509",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cca6538642a422d819787650a180166",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/1.16M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "440ae64b51324fd18594da3ed62ee4a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/73.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe128fc9981846c697b772f8329468f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/299k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4c90c9da3e64d3bba6e9d4f9c8664c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c85f43564f4a4003a0e216e6603e3147",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/27739 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8760aa1429349049c5a080606edfd7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/408 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "859ba2873d4a46cbac6d76a05448c7d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/1725 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "uploaded_dataset = load_dataset(new_dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "71e2239b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['label', 'sentence1', 'sentence2', 'category'],\n",
       "        num_rows: 27739\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['label', 'sentence1', 'sentence2', 'category'],\n",
       "        num_rows: 408\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['label', 'sentence1', 'sentence2', 'category'],\n",
       "        num_rows: 1725\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uploaded_dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:llama] *",
   "language": "python",
   "name": "conda-env-llama-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
